"""OpenAIë¥¼ í™œìš©í•œ ì§ˆë¬¸ ìƒì„± ì „ëµ êµ¬í˜„ì²´

ì‹œë‹ˆì–´ í”¼ë“œë°± ë°˜ì˜:
- Helper ë©”ì„œë“œë¡œ _build_prompt ë¦¬íŒ©í† ë§ (ê°€ë…ì„±/ìœ ì§€ë³´ìˆ˜ì„±)
- RAG ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 5ê°œ)
- System Prompt ê°•í™” (ê°€ì¡± ëŒ€í™” ë§¥ë½)
"""
import logging
from typing import Optional, List
from datetime import datetime

from app.question.base import QuestionGenerator
from app.question.models import QuestionGenerateRequest, QuestionInstanceResponse
from app.adapters.openai_client import OpenAIClient
from app.core.config import settings

logger = logging.getLogger(__name__)


class OpenAIQuestionGenerator(QuestionGenerator):
    def __init__(self):
        self.client = OpenAIClient()

    async def generate(
        self,
        request: QuestionGenerateRequest,
        past_answers: Optional[List[dict]] = None
    ) -> QuestionInstanceResponse:
        """ì§ˆë¬¸ ìƒì„±"""
        # RAG í™œì„±í™” ì—¬ë¶€
        rag_enabled = past_answers is not None and len(past_answers) > 0
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(request, past_answers)
        
        # OpenAI í˜¸ì¶œ
        response = await self._call_openai(prompt)
        
        # ì‘ë‹µ íŒŒì‹±
        content = self._parse_response(response)

        # ì‹ ë¢°ë„ í‰ê°€
        confidence, meta = self._evaluate_generation(
            content=content,
            language=request.language or "ko",
            tone=request.tone,
            max_len=settings.max_question_length
        )

        # RAG ë©”íƒ€ë°ì´í„° ì¶”ê°€
        meta["ragEnabled"] = rag_enabled
        meta["ragContextCount"] = len(past_answers) if past_answers else 0
        if rag_enabled:
            meta["ragVersion"] = "v1"
        
        return QuestionInstanceResponse(
            content=content,
            generated_by="ai",
            generation_model=settings.default_model,
            generation_parameters={
                "max_completion_tokens": settings.max_tokens
            },
            generation_prompt=prompt,
            generation_metadata=meta,
            generation_confidence=confidence
        )
    
    def _build_rag_context(self, past_answers: List[dict]) -> str:
        """
        RAG ì»¨í…ìŠ¤íŠ¸ ì„¹ì…˜ ìƒì„±
        
        ê°œì„ :
        - ìµœëŒ€ 5ê°œë¡œ ì œí•œ (í† í°/ë¹„ìš© ì ˆê°, Lost in the Middle ë°©ì§€)
        - ëª…í™•í•œ ì£¼ì„ ì¶”ê°€
        """
        if not past_answers or len(past_answers) == 0:
            return ""
        
        lines = []
        lines.append("=== ğŸ“š ê³¼ê±° ëŒ€í™” ë§¥ë½ (ì°¸ê³ ìš©) ===")
        lines.append("ì‚¬ìš©ìê°€ ì´ì „ì— ë‹µë³€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ë” ê°œì¸í™”ëœ ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.")
        lines.append("")
        
        # ìµœëŒ€ 5ê°œë¡œ ì œí•œ (ë¹„ìš©/ì„±ëŠ¥ ìµœì í™”)
        # ì„œë¹„ìŠ¤ ë ˆì´ì–´ì—ì„œ top_kë¡œ ì´ë¯¸ í•„í„°ë§í–ˆì§€ë§Œ, ì¶”ê°€ ë³´í˜¸
        limited_answers = past_answers[:5]
        
        for idx, item in enumerate(limited_answers, 1):
            question = item.get("question", "")
            answer = item.get("answer", "")
            timestamp = item.get("timestamp", "")
            
            # ìƒëŒ€ì  ì‹œê°„ í‘œì‹œ
            time_str = ""
            if timestamp:
                try:
                    past_time = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                    now = datetime.now(past_time.tzinfo)
                    delta = now - past_time
                    if delta.days > 0:
                        time_str = f"({delta.days}ì¼ ì „)"
                    else:
                        time_str = "(ì˜¤ëŠ˜)"
                except Exception:
                    pass
            
            lines.append(f"{idx}. {time_str}")
            lines.append(f"   Q: {question}")
            lines.append(f"   A: {answer}")
            lines.append("")
        
        # 5ê°œ ì´ˆê³¼ ì‹œ ì•Œë¦¼
        if len(past_answers) > 5:
            lines.append(f"ğŸ’¡ (ì´ {len(past_answers)}ê°œ ë‹µë³€ ì¤‘ ìƒìœ„ 5ê°œë§Œ í‘œì‹œ)")
            lines.append("")
        
        lines.append("ğŸ‘‰ ìœ„ ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬:")
        lines.append("- ì‚¬ìš©ìê°€ ê´€ì‹¬ ìˆì–´í•˜ëŠ” ì£¼ì œë¥¼ ë°˜ì˜í•˜ì„¸ìš”")
        lines.append("- ì´ì „ ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ìƒí™©ì„ í™œìš©í•˜ì„¸ìš”")
        lines.append("- ë‹¨, ê³¼ê±° ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”")
        lines.append("")
        
        return "\n".join(lines)
    
    def _build_answer_analysis_context(self, request: QuestionGenerateRequest) -> str:
        """ë‹µë³€ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì„¹ì…˜ ìƒì„± (íŒ”ë¡œì—… ëª¨ë“œ)"""
        if not request.answer_analysis:
            return ""
        
        lines = []
        lines.append("=== ğŸ“Œ ì‚¬ìš©ìì˜ ë‹µë³€ ë‚´ìš© (í•µì‹¬!) ===")
        
        analysis = request.answer_analysis
        summary = analysis.summary
        categories = analysis.categories
        scores = analysis.scores
        keywords = analysis.keywords
        
        if summary:
            lines.append(f"ë‹µë³€ ìš”ì•½: {summary}")
        if keywords:
            lines.append(f"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(keywords)}")
        if categories:
            lines.append(f"ì£¼ì œ: {', '.join(categories)}")
        
        # ê°ì • ë¶„ì„
        if scores and scores.emotion:
            emo = scores.emotion
            emotions = []
            if emo.sadness and emo.sadness > 0.4:
                emotions.append("ìŠ¬í””/ê·¸ë¦¬ì›€")
            if emo.joy and emo.joy > 0.4:
                emotions.append("ê¸°ì¨")
            if emo.anger and emo.anger > 0.4:
                emotions.append("ë¶„ë…¸")
            if emotions:
                lines.append(f"ğŸ’­ ê°ì •: {', '.join(emotions)}")
        
        lines.append("")
        lines.append("ğŸ‘‰ íŒ”ë¡œì—… ì „ëµ:")
        lines.append("- ë‹µë³€ì— êµ¬ì²´ì ì¸ ê³ ìœ ëª…ì‚¬(ì˜í™”/ë…¸ë˜ ì œëª©, ì¥ì†Œ, ë¸Œëœë“œ ë“±)ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ê²ƒì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë³´ì„¸ìš”.")
        lines.append("- ì˜ˆ: 'í—Œí„°í—Œí„° ì˜¤í”„ë‹' -> 'ì˜¤, ê·¸ ì• ë‹ˆ ì¬ë°Œë‚˜ìš”?' ë˜ëŠ” 'ì–´ë–¤ ë²„ì „ ì˜¤í”„ë‹ ì¢‹ì•„í•˜ì„¸ìš”?'")
        lines.append("- âŒ ì ˆëŒ€ ê¸ˆì§€: êµ¬ì²´ì ì¸ ë‹µë³€ì„ ë¬´ì‹œí•˜ê³  ë‹¤ì‹œ 'ë…¸ë˜'ë‚˜ 'ì·¨ë¯¸' ê°™ì€ í° ë²”ì£¼ë¡œ ì§ˆë¬¸í•˜ê¸°")
        lines.append("- ê¸ì •ì  ê°ì •ì´ë©´ ê·¸ ì£¼ì œë¥¼ ë” ê¹Šì´ íŒŒê³ ë“œì„¸ìš”.")
        lines.append("- ë¶€ì •ì  ê°ì •ì´ë©´ í™”ì œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì „í™˜í•˜ì„¸ìš”.")
        lines.append("")
        
        return "\n".join(lines)
    
    def _build_generation_rules(self) -> str:
        """ì§ˆë¬¸ ìƒì„± ê·œì¹™ ì„¹ì…˜"""
        lines = []
        lines.append("=== ìƒì„± ê·œì¹™ ===")
        lines.append("1) ì§§ê³  ê°„ê²°í•˜ê²Œ: í•œ ë¬¸ì¥, 40ì ì´ë‚´ ê¶Œì¥")
        lines.append("2) ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬: '~ë‚˜ìš”?', '~ì–´ìš”?', '~ìˆì–´ìš”?' ê°™ì€ í¸ì•ˆí•œ ì˜ë¬¸í˜•")
        lines.append("3) âš ï¸ ê¸ˆì§€ í‘œí˜„:")
        lines.append("   - í˜•ì‹ì : 'ë– ì˜¬ë¦¬ì‹œê³ ', 'ë§ì”€í•´ ì£¼ì„¸ìš”', 'ìì„¸íˆ', 'êµ¬ì²´ì ìœ¼ë¡œ'")
        lines.append("   - ë¬´ê±°ì›€: 'ìˆœê°„', 'ê¸°ì–µ', 'ë– ì˜¤ë¥´ë‚˜ìš”', 'ëŠê¼ˆë‚˜ìš”'")
        lines.append("   - ì•µë¬´ìƒˆ í™”ë²•: ë‹µë³€ì„ ë‹¨ìˆœíˆ ë”°ë¼í•˜ì§€ ë§ˆì„¸ìš”. (ë‹¨, êµ¬ì²´ì ì¸ ê³ ìœ ëª…ì‚¬ëŠ” ì–¸ê¸‰í•´ë„ ì¢‹ìŠµë‹ˆë‹¤)")
        lines.append("4) ë¬¼ìŒí‘œ(?)ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤")
        lines.append("")
        
        return "\n".join(lines)
    
    def _build_prompt(
        self,
        request: QuestionGenerateRequest,
        past_answers: Optional[List[dict]] = None
    ) -> str:
        """
        ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
        
        ë¦¬íŒ©í† ë§: Helper ë©”ì„œë“œë¡œ ì„¹ì…˜ ë¶„ë¦¬ (ê°€ë…ì„±/ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ)
        """
        lines = []
        lines.append("=== ğŸ¯ ë¯¸ì…˜ ===")
        lines.append("ê°€ì¡± ê°„ì˜ ëŒ€í™”ë¥¼ ì´ì–´ì£¼ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
        lines.append("")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
        rag_context = self._build_rag_context(past_answers or [])
        if rag_context:
            lines.append(rag_context)
        
        # ì´ì „ ì§ˆë¬¸ (ë² ì´ìŠ¤)
        lines.append("=== ì´ì „ ì§ˆë¬¸ ===")
        lines.append(f"{request.content}")
        lines.append("")
        
        # ë§¥ë½ ì •ë³´
        ctx = []
        if request.category:
            ctx.append(f"ì¹´í…Œê³ ë¦¬: {request.category}")
        if request.tone:
            ctx.append(f"í†¤: {request.tone}")
        if request.language:
            ctx.append(f"ì–¸ì–´: {request.language}")
        if request.tags:
            ctx.append(f"íƒœê·¸: {', '.join(request.tags)}")
        if request.subject_required is not None:
            ctx.append(f"ì£¼ì œ ì¸ë¬¼ í•„ìš”: {request.subject_required}")
        
        if ctx:
            lines.append("=== ë§¥ë½ ===")
            lines.extend(ctx)
            lines.append("")

        # ë‹µë³€ ë¶„ì„ (íŒ”ë¡œì—… ëª¨ë“œ)
        answer_context = self._build_answer_analysis_context(request)
        if answer_context:
            lines.append(answer_context)

        # ìƒì„± ê·œì¹™
        lines.append(self._build_generation_rules())
        
        # ì˜ˆì‹œ (íŒ”ë¡œì—… ëª¨ë“œì¼ ë•Œë§Œ)
        if request.answer_analysis and request.answer_analysis.keywords:
            lines.append("ğŸ“ ë³€í™˜ ì˜ˆì‹œ:")
            lines.append("  â†’ ë‹µë³€: 'í—Œí„°í—Œí„° ì˜¤í”„ë‹ ë“£ëŠ” ì¤‘'")
            lines.append("  â†’ âŒ ë‚˜ì¨: 'ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ê°€ ë­”ê°€ìš”?' (êµ¬ì²´ì  ë‚´ìš© ë¬´ì‹œ)")
            lines.append("  â†’ âœ… ì¢‹ìŒ: 'ì˜¤, í—Œí„°í—Œí„°! êµ¬ì‘ì´ë‘ ì‹ ì‘ ì¤‘ì— ì–´ë–¤ ê±° ë³´ì„¸ìš”?' (êµ¬ì²´ì  ê´€ì‹¬)")
        lines.append("")
        
        lines.append("ìœ„ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 1ê°œë§Œ ìƒì„±í•˜ì„¸ìš”:")
        
        return "\n".join(lines)

    async def _call_openai(self, prompt: str) -> str:
        """
        OpenAI API í˜¸ì¶œ
        
        ê°œì„ : System Prompt ê°•í™” (ê°€ì¡± ëŒ€í™” ë§¥ë½ ëª…í™•í™”)
        """
        return await self.client.chat_completion(
            [
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ê°€ì¡± ê°„ì˜ ëŒ€í™”ë¥¼ ì´ì–´ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                        "ì‚¬ìš©ìê°€ ë¶€ëª¨ë‹˜ì´ë‚˜ ìë…€ì™€ ëŒ€í™”í•  ê±°ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. "
                        "\n\n"
                        "ì¹œêµ¬ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë˜, ê°€ì¡± ê´€ê³„ì— ì í•©í•œ ë”°ëœ»í•˜ê³  í¸ì•ˆí•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”. "
                        "ì¹´í†¡ìœ¼ë¡œ ê°€ì¡±ì—ê²Œ 'ìš”ì¦˜ ì–´ë•Œ?', 'ì¬ë°ŒëŠ” ì¼ ìˆì–´?' ë¬»ë“¯ì´ ê°€ë³ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”. "
                        "\n\n"
                        "ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ: "
                        "1) êµ¬ì²´ì ì¸ ê³ ìœ ëª…ì‚¬ê°€ ë‚˜ì™”ëŠ”ë° ëœ¬ê¸ˆì—†ì´ í¬ê´„ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° "
                        "2) ì•µë¬´ìƒˆì²˜ëŸ¼ ë‹µë³€ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ìŠê¸° "
                        "3) ë¬´ê²ê±°ë‚˜ í˜•ì‹ì ì¸ í‘œí˜„ ('ìˆœê°„', 'ê¸°ì–µ', 'ë– ì˜¤ë¥´ë‚˜ìš”') "
                        "4) ì‹¬ë¦¬ìƒë‹´ ê°™ì€ ì§ˆë¬¸ ('ì–´ë–¤ ê°ì •ì´', 'ì–´ë–¤ ì˜ë¯¸ê°€') "
                        "5) ë¶€ì •ì  ê°ì •ì„ ê³„ì† íŒŒê³ ë“¤ê¸°"
                    ),
                },
                {"role": "user", "content": prompt},
            ]
        )

    def _parse_response(self, response: str) -> str:
        """
        LLM ì‘ë‹µ íŒŒì‹± (ë°©ì–´ ë¡œì§ í¬í•¨)
        - ì ‘ë‘ì‚¬ ì œê±°: 'ì§ˆë¬¸:', 'ë‹µë³€:', 'Question:', 'Answer:'
        - ë”°ì˜´í‘œ ì œê±°: ", ', ", ', ', ' ë“±
        - ê³µë°± ì œê±°
        - ì²« ë²ˆì§¸ ìœ íš¨í•œ ì¤„ë§Œ ë°˜í™˜
        """
        text = response.strip()
        
        # ì ‘ë‘ì‚¬ ì œê±°
        prefixes = ['ì§ˆë¬¸:', 'ë‹µë³€:', 'Question:', 'Answer:', 'ì§ˆë¬¸ :', 'ë‹µë³€ :']
        for prefix in prefixes:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
                break
        
        # ë”°ì˜´í‘œ ì œê±° (ì˜ë¬¸, í•œê¸€)
        quotes = ['"', "'", '"', '"', ''', ''']
        while text and text[0] in quotes:
            text = text[1:]
        while text and text[-1] in quotes:
            text = text[:-1]
        
        text = text.strip()
        
        # ì²« ë²ˆì§¸ ìœ íš¨í•œ ì¤„ ë°˜í™˜
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if line:
                return line
        
        return text

    def _evaluate_generation(
        self,
        content: str,
        language: str,
        tone: Optional[str],
        max_len: int
    ) -> tuple[float, dict]:
        """ìƒì„± í’ˆì§ˆ í‰ê°€"""
        try:
            score = 1.0
            
            meta = {
                "questionLength": len(content),
                "hasQuestionMark": "?" in content or content.endswith("ìš”") or content.endswith("ê°€ìš”"),
                "language": language,
                "tone": tone
            }
            
            # ê¸¸ì´ ì²´í¬
            if len(content) > max_len:
                score -= 0.2
            
            # ë¬¼ìŒí‘œ/ì–´ë¯¸ ì²´í¬
            if not meta["hasQuestionMark"]:
                score -= 0.1
            
            score = max(0.0, min(1.0, score))
            return score, meta
        
        except Exception:
            return 0.5, {"error": "evaluation_failed"}
